{
    "summary": "Voyager AI agent explores Minecraft, learns autonomously, outperforms SOTA, generalizes tasks, MIT licensed, expected 2023 Arxiv preprint (Arxiv-2305.16291).",
    "details": [
        {
            "comment": "This code introduces Voyager, an embodied agent powered by large language models that continuously explores Minecraft, acquires skills, and discovers new things without human intervention. It consists of three main components: an automatic curriculum for exploration, a language model, and an interactive environment in Minecraft.",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":0-23",
            "content": "# Voyager: An Open-Ended Embodied Agent with Large Language Models\n<div align=\"center\">\n[[Website]](https://voyager.minedojo.org/)\n[[Arxiv]](https://arxiv.org/abs/2305.16291)\n[[PDF]](https://voyager.minedojo.org/assets/documents/voyager.pdf)\n[[Tweet]](https://twitter.com/DrJimFan/status/1662115266933972993?s=20)\n[![Python Version](https://img.shields.io/badge/Python-3.9-blue.svg)](https://github.com/MineDojo/Voyager)\n[![GitHub license](https://img.shields.io/github/license/MineDojo/Voyager)](https://github.com/MineDojo/Voyager/blob/main/LICENSE)\n______________________________________________________________________\nhttps://github.com/MineDojo/Voyager/assets/25460983/ce29f45b-43a5-4399-8fd8-5dd105fd64f2\n![](images/pull.png)\n</div>\nWe introduce Voyager, the first LLM-powered embodied lifelong learning agent\nin Minecraft that continuously explores the world, acquires diverse skills, and\nmakes novel discoveries without human intervention. Voyager consists of three\nkey components: 1) an automatic curriculum that maximizes exploration, 2) an"
        },
        {
            "comment": "This code snippet describes Voyager's functionality: a skill library for storing and retrieving complex behaviors, an iterative prompting mechanism incorporating feedback, and interaction with GPT-4 through blackbox queries. It shows strong in-context lifelong learning capabilities, outperforming prior SOTA in Minecraft, generalizing to novel tasks from scratch. The codebase is under MIT License.",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":24-37",
            "content": "ever-growing skill library of executable code for storing and retrieving complex\nbehaviors, and 3) a new iterative prompting mechanism that incorporates environment\nfeedback, execution errors, and self-verification for program improvement.\nVoyager interacts with GPT-4 via blackbox queries, which bypasses the need for\nmodel parameter fine-tuning. The skills developed by Voyager are temporally\nextended, interpretable, and compositional, which compounds the agent\u2019s abilities\nrapidly and alleviates catastrophic forgetting. Empirically, Voyager shows\nstrong in-context lifelong learning capability and exhibits exceptional proficiency\nin playing Minecraft. It obtains 3.3\u00d7 more unique items, travels 2.3\u00d7 longer\ndistances, and unlocks key tech tree milestones up to 15.3\u00d7 faster than prior SOTA.\nVoyager is able to utilize the learned skill library in a new Minecraft world to\nsolve novel tasks from scratch, while other techniques struggle to generalize.\nIn this repo, we provide Voyager code. This codebase is under [MIT License](LICENSE)."
        },
        {
            "comment": "This code provides instructions for installing Voyager, a tool that requires Python \u2265 3.9 and Node.js \u2265 16.13.0. It outlines steps for Python, Node.js, Minecraft instance, and Fabric mods installation with links to additional tutorials.",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":39-71",
            "content": "# Installation\nVoyager requires Python \u2265 3.9 and Node.js \u2265 16.13.0. We have tested on Ubuntu 20.04, Windows 11, and macOS. You need to follow the instructions below to install Voyager.\n## Python Install\n```\ngit clone https://github.com/MineDojo/Voyager\ncd Voyager\npip install -e .\n```\n## Node.js Install\nIn addition to the Python dependencies, you need to install the following Node.js packages:\n```\ncd voyager/env/mineflayer\nnpm install -g npx\nnpm install\ncd mineflayer-collectblock\nnpx tsc\ncd ..\nnpm install\n```\n## Minecraft Instance Install\nVoyager depends on Minecraft game. You need to install Minecraft game and set up a Minecraft instance.\nFollow the instructions in [Minecraft Login Tutorial](installation/minecraft_instance_install.md) to set up your Minecraft Instance.\n## Fabric Mods Install\nYou need to install fabric mods to support all the features in Voyager. Remember to use the correct Fabric version of all the mods. \nFollow the instructions in [Fabric Mods Install](installation/fabric_mods_install.md) to install the mods."
        },
        {
            "comment": "To use Voyager, ensure you have an OpenAI API key and install the required dependencies. Create an azure_login dictionary with your client ID, redirect URL, secret value (optional), and version. Set openai_api_key to YOUR_API_KEY. Instantiate Voyager with these settings. First-time Azure Login users will generate a config file following instructions. For Azure Login, open the world and LAN, then run learn(). The game will start soon.",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":73-99",
            "content": "# Getting Started\nVoyager uses OpenAI's GPT-4 as the language model. You need to have an OpenAI API key to use Voyager. You can get one from [here](https://platform.openai.com/account/api-keys).\nAfter the installation process, you can run Voyager by:\n```python\nfrom voyager import Voyager\n# You can also use mc_port instead of azure_login, but azure_login is highly recommended\nazure_login = {\n    \"client_id\": \"YOUR_CLIENT_ID\",\n    \"redirect_url\": \"https://127.0.0.1/auth-response\",\n    \"secret_value\": \"[OPTIONAL] YOUR_SECRET_VALUE\",\n    \"version\": \"fabric-loader-0.14.18-1.19\", # the version Voyager is tested on\n}\nopenai_api_key = \"YOUR_API_KEY\"\nvoyager = Voyager(\n    azure_login=azure_login,\n    openai_api_key=openai_api_key,\n)\n# start lifelong learning\nvoyager.learn()\n```\n* If you are running with `Azure Login` for the first time, it will ask you to follow the command line instruction to generate a config file.\n* For `Azure Login`, you also need to select the world and open the world to LAN by yourself. After you run `voyager.learn()` the game will pop up soon, you need to:"
        },
        {
            "comment": "1. The code provides instructions to set up a Minecraft world for Voyager learning.\n2. Users can resume from a checkpoint or run Voyager with a specific skill library.\n3. Required credentials, directories and settings need to be provided when instantiating the Voyager class.",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":100-129",
            "content": "  1. Select `Singleplayer` and press `Create New World`.\n  2. Set Game Mode to `Creative` and Difficulty to `Peaceful`.\n  3. After the world is created, press `Esc` key and press `Open to LAN`.\n  4. Select `Allow cheats: ON` and press `Start LAN World`. You will see the bot join the world soon. \n# Resume from a checkpoint during learning\nIf you stop the learning process and want to resume from a checkpoint later, you can instantiate Voyager by:\n```python\nfrom voyager import Voyager\nvoyager = Voyager(\n    azure_login=azure_login,\n    openai_api_key=openai_api_key,\n    ckpt_dir=\"YOUR_CKPT_DIR\",\n    resume=True,\n)\n```\n# Run Voyager for a specific task with a learned skill library\nIf you want to run Voyager for a specific task with a learned skill library, you should first pass the skill library directory to Voyager:\n```python\nfrom voyager import Voyager\n# First instantiate Voyager with skill_library_dir.\nvoyager = Voyager(\n    azure_login=azure_login,\n    openai_api_key=openai_api_key,\n    skill_library_dir=\"./skill_library/trial1\", # Load a learned skill library."
        },
        {
            "comment": "This code sets up the Voyager agent with a specified checkpoint directory and disables resuming from a skill library because this task is not learning-based. After setting up, it decomposes a given task into sub-goals using Voyager's task decomposition functionality. Finally, it runs inference on these sub-goals using the learned skill library. Valid skill libraries can be found at [Learned Skill Libraries](skill_library/README.md).",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":130-156",
            "content": "    ckpt_dir=\"YOUR_CKPT_DIR\", # Feel free to use a new dir. Do not use the same dir as skill library because new events will still be recorded to ckpt_dir. \n    resume=False, # Do not resume from a skill library because this is not learning.\n)\n```\nThen, you can run task decomposition. Notice: Occasionally, the task decomposition may not be logical. If you notice the printed sub-goals are flawed, you can rerun the decomposition.\n```python\n# Run task decomposition\ntask = \"YOUR TASK\" # e.g. \"Craft a diamond pickaxe\"\nsub_goals = voyager.decompose_task(task=task)\n```\nFinally, you can run the sub-goals with the learned skill library:\n```python\nvoyager.inference(sub_goals=sub_goals)\n```\nFor all valid skill libraries, see [Learned Skill Libraries](skill_library/README.md).\n# FAQ\nIf you have any questions, please check our [FAQ](FAQ.md) first before opening an issue.\n# Paper and Citation\nIf you find our work useful, please consider citing us! \n```bibtex\n@article{wang2023voyager,\n  title   = {Voyager: An Open-Ended Embodied Agent with Large Language Models},"
        },
        {
            "comment": "The code block represents the author, year, and journal information for a research paper. The paper is expected to be published in 2023 as an arXiv preprint with identifier Arxiv-2305.16291.",
            "location": "\"/media/root/Prima/works/Voyager/docs/src/README.md\":157-163",
            "content": "  author  = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},\n  year    = {2023},\n  journal = {arXiv preprint arXiv: Arxiv-2305.16291}\n}\n```\nDisclaimer: This project is strictly for research purposes, and not an official product from NVIDIA."
        }
    ]
}